{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.05525792  0.62473766 -2.7352535   2.30473324]\n",
      "   Amount  Severity       Age  Private Attorney  Marital Status  Specialty  \\\n",
      "0  105148 -0.383544  1.026307                 1       -1.055258   1.110174   \n",
      "1   58102 -0.864510 -0.842289                 1        0.624738  -0.355779   \n",
      "2  420188  1.059352 -1.145304                 1       -1.055258   0.783230   \n",
      "3  143699 -0.383544  1.430328                 1        0.624738  -0.895084   \n",
      "4  363654 -0.864510 -1.044299                 1        0.624738  -0.355779   \n",
      "\n",
      "   Gender  Insurance_Medicare/Medicaid  Insurance_No Insurance  \\\n",
      "0       1                          0.0                     0.0   \n",
      "1       1                          0.0                     0.0   \n",
      "2       0                          0.0                     1.0   \n",
      "3       0                          0.0                     0.0   \n",
      "4       0                          0.0                     0.0   \n",
      "\n",
      "   Insurance_Private  Insurance_Unknown  Insurance_Workers Compensation  \n",
      "0                1.0                0.0                             0.0  \n",
      "1                0.0                1.0                             0.0  \n",
      "2                0.0                0.0                             0.0  \n",
      "3                0.0                1.0                             0.0  \n",
      "4                1.0                0.0                             0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_17268\\3055527262.py:52: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({'Gender':{'Male':1,'Female':0}},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Importing Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "dataset = pd.read_csv(r\"C:\\Users\\moham\\Desktop\\ML-project\\Data\\medicalmalpractice.csv\")\n",
    "\n",
    "\n",
    "#Reading the Train data\n",
    "train_data = pd.read_csv('./data/raw/train.csv')\n",
    "#Reading the Test data \n",
    "test_data = pd.read_csv('./data/raw/test.csv')\n",
    "\n",
    "#Based on performed EDA previously , there is an unkown/missing values for Marital Status column and Insurance Column \n",
    "#\"Unknown\" in Insurance column will be treated  as a Separate Category , since it represents 30% of values and it have a very high impact on target label\n",
    "#\"Unkown\" in Matrial Status will be replaced with most frequent value , since it does not represent a high percantage of values , and it got less impact on target label\n",
    "\n",
    "\n",
    "#Function for handling missing values of Marital Status\n",
    "def handle_missing_values(df):\n",
    "    \n",
    "    # Finding most frequent value to replace with\n",
    "    most_frequent_category= df[\"Marital Status\"].mode()[0]\n",
    "    \n",
    "    # Replace missing values/Unkowns with most_frequent_category\n",
    "    df[\"Marital Status\"] = df[\"Marital Status\"].replace(4, most_frequent_category) # 4 stands for Unkown Marital Status \n",
    "    \n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "#Features Encoding\n",
    "\n",
    "# Target Encoding for Specialty Column , since it gives slightly better results on any model performance,\n",
    "# and the splitted train set off test set will prevent data leakge.\n",
    "\n",
    "#Function for Target Encoding\n",
    "def target_encoder(df):\n",
    "\n",
    "    #Calculating the mean target value (Amount) for each category in Specialty\n",
    "    specialty_means = df.groupby(\"Specialty\")['Amount'].mean()\n",
    "\n",
    "    # Mapping means to the Specialty column\n",
    "    df['Specialty'] = df[\"Specialty\"].map(specialty_means)\n",
    "    return df\n",
    "    \n",
    "\n",
    "# Label Encoding Function for Gender & Marital Status\n",
    "def label_encoder(df):\n",
    "    #For Gender Column\n",
    "    df.replace({'Gender':{'Male':1,'Female':0}},inplace=True)\n",
    "    \n",
    "    #For Marital Status Column\n",
    "    df.replace({'Marital Status':{'Married':4,'Divorced':3,'Single':2,'Widowed':1}},inplace=True )\n",
    "    return df\n",
    "\n",
    "\n",
    "#One hot Encoding Function for Insurance Column\n",
    "def one_hot_encoder(df):\n",
    "  encoder = OneHotEncoder(sparse_output=False)\n",
    "  encoded_data = encoder.fit_transform(df[['Insurance']])\n",
    "  encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['Insurance']))\n",
    "  df = pd.concat([df, encoded_df], axis=1)\n",
    "  # Dropping the original Insurance column\n",
    "  df.drop('Insurance', axis=1, inplace=True)\n",
    "  return df\n",
    "\n",
    "#Features Scaler Function\n",
    "def scaler(df,features):\n",
    "    scaler = StandardScaler()\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#Applying missing values handlers for training & testing sets\n",
    "all_dataset_processed=handle_missing_values(dataset)\n",
    "train_data_processed=handle_missing_values(train_data)\n",
    "test_data_processed=handle_missing_values(test_data)\n",
    "#Applying encoding functions for training & testing sets\n",
    "funcs = [target_encoder,label_encoder,one_hot_encoder]\n",
    "\n",
    "for f in funcs:\n",
    "    train_data_processed= f(train_data_processed)\n",
    "    test_data_processed=f(test_data_processed)\n",
    "    all_dataset_processed=f(all_dataset_processed)\n",
    "\n",
    "#Applying scaler function\n",
    "features_to_scale = [\"Severity\",\"Age\",\"Marital Status\",\"Specialty\"]\n",
    "scaler(train_data_processed,features_to_scale)\n",
    "scaler(test_data_processed,features_to_scale)\n",
    "scaler(all_dataset_processed,features_to_scale)\n",
    "\n",
    "\n",
    "\n",
    "#Checking if 4 value is removed from Martial Status column\n",
    "unique_values = train_data_processed['Marital Status'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "#Checking some samples of preprocessed data\n",
    "print(train_data_processed.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Creating folder for processed data\n",
    "#data_path = os.path.join(\"data\",\"all_dataset\")\n",
    "#os.makedirs(data_path)\n",
    "\n",
    "# Storing Processed training & testing sets as outputs\n",
    "\n",
    "#train_data_processed.to_csv(os.path.join(data_path,\"train_processed.csv\"),index=False)\n",
    "#test_data_processed.to_csv(os.path.join(data_path,\"test_processed.csv\"),index=False)\n",
    "#all_dataset_processed.to_csv(os.path.join(data_path,\"all_dataset_processed.csv\"),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital Status\n",
       " 0.624046    51582\n",
       "-1.053163    22802\n",
       "-2.730373     3832\n",
       " 2.301256      994\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dataset_processed[\"Marital Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= train_data_processed.drop(\"Amount\", axis=1)  #training data faeutures\n",
    "y_train = train_data_processed[\"Amount\"] # training target fetuatre\n",
    "X_test= test_data_processed.drop(\"Amount\", axis=1) #testing data feautres\n",
    "y_test=test_data_processed[\"Amount\"] #testing target fetuatre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for training data: 112510.82207201603\n",
      "R2 Score for training data: 0.2981866925414671\n",
      "Mean Absolute Error (MAE) for testing data: 113861.4662373029\n",
      "R2 Score for testing data: 0.29679607517797124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "model = LinearRegression()\n",
    "# Train the model on the training data\n",
    "training_data_predection=model.fit(X_train, y_train)\n",
    "\n",
    "#prediction on training data \n",
    "training_data_predection = model.predict(X_train)\n",
    "\n",
    "#evaluate the model on training data\n",
    "mse = mean_absolute_error(y_train, training_data_predection)\n",
    "r2 = r2_score(y_train, training_data_predection)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) for training data: {mse}\")\n",
    "print(f\"R2 Score for training data: {r2}\")\n",
    "\n",
    "testing_data_predection =model.predict(X_test)\n",
    "\n",
    "# evaluate the model on testing data\n",
    "mse = mean_absolute_error(y_test, testing_data_predection)\n",
    "r2 = r2_score(y_test, testing_data_predection)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) for testing data: {mse}\")\n",
    "print(f\"R2 Score for testing data: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with standard scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Performance:\n",
      "R² Score: 0.6825\n",
      "Mean Absolute Error (MAE): 66290.2170\n",
      "\n",
      "Testing Data Performance:\n",
      "R² Score: 0.6157\n",
      "Mean Absolute Error (MAE): 73749.9137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# create KNN model\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# train the model \n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = knn.predict(X_train)  \n",
    "y_test_pred = knn.predict(X_test)  \n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "print(\"Training Data Performance:\")\n",
    "print(f\"R² Score: {r2_train:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_train:.4f}\")\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTesting Data Performance:\")\n",
    "print(f\"R² Score: {r2_test:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without using standard scaler \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Performance:\n",
      "R² Score: 0.6199\n",
      "Mean Absolute Error (MAE): 73775.4050\n",
      "\n",
      "Testing Data Performance:\n",
      "R² Score: 0.5066\n",
      "Mean Absolute Error (MAE): 83861.2478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = knn.predict(X_train)  \n",
    "y_test_pred = knn.predict(X_test)    \n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "print(\"Training Data Performance:\")\n",
    "print(f\"R² Score: {r2_train:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_train:.4f}\")\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTesting Data Performance:\")\n",
    "print(f\"R² Score: {r2_test:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using min max scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Performance with MinMaxScaler:\n",
      "R² Score: 0.6851\n",
      "Mean Absolute Error (MAE): 66022.8201\n",
      "\n",
      "Testing Data Performance with MinMaxScaler:\n",
      "R² Score: 0.6167\n",
      "Mean Absolute Error (MAE): 73641.9655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = knn.predict(X_train_scaled)\n",
    "y_test_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "print(\"Training Data Performance with MinMaxScaler:\")\n",
    "print(f\"R² Score: {r2_train:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_train:.4f}\")\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTesting Data Performance with MinMaxScaler:\")\n",
    "print(f\"R² Score: {r2_test:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Performance with RandomForest:\n",
      "R² Score: 0.7963\n",
      "MAE: 46857.3077\n",
      "\n",
      "Testing Data Performance with RandomForest:\n",
      "R² Score: 0.5448\n",
      "MAE: 76922.7037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Training Data Performance with RandomForest:\")\n",
    "print(f\"R² Score: {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_train, y_train_pred):.4f}\")\n",
    "\n",
    "print(\"\\nTesting Data Performance with RandomForest:\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_test_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R² Scores: [0.56588184 0.57557669 0.56395382 0.56591628 0.57234951]\n",
      "Mean CV R²: 0.5687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2')\n",
    "print(f\"Cross-Validation R² Scores: {scores}\")\n",
    "print(f\"Mean CV R²: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 15, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best R² Score: 0.6548438474338945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best R² Score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best KNN Parameters: {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# إعداد معلمات البحث لتحسين KNN باستخدام GridSearchCV\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': [5, 10, 15, 20, 25],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# إنشاء نموذج KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# تنفيذ GridSearchCV لتحسين KNN\n",
    "search_knn = GridSearchCV(knn, param_grid=knn_param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "# تدريب النموذج KNN\n",
    "search_knn.fit(X_train, y_train)\n",
    "\n",
    "# اختيار أفضل نموذج من GridSearchCV\n",
    "best_knn = search_knn.best_estimator_\n",
    "\n",
    "# طباعة أفضل المعلمات\n",
    "print(\"Best KNN Parameters:\", search_knn.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Performance:\n",
      "R² Score: 0.6864\n",
      "MAE: 66690.2891\n",
      "\n",
      "Testing Data Performance:\n",
      "R² Score: 0.6077\n",
      "MAE: 75063.8808\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Creating the individual models\n",
    "knn = KNeighborsRegressor(n_neighbors=15)\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=15, max_features='log2', min_samples_split=10, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, )\n",
    "\n",
    "# Wrapping XGBRegressor to make it compatible with VotingRegressor\n",
    "xgb_wrapped = TransformedTargetRegressor(regressor=xgb)\n",
    "\n",
    "# Creating the ensemble model using VotingRegressor\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('knn', knn),\n",
    "    ('rf', rf),\n",
    "    ('xgb', xgb_wrapped)\n",
    "])\n",
    "\n",
    "# Training the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation on training data\n",
    "y_train_pred = ensemble_model.predict(X_train)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "print(f\"Training Data Performance:\")\n",
    "print(f\"R² Score: {train_r2:.4f}\")\n",
    "print(f\"MAE: {train_mae:.4f}\")\n",
    "\n",
    "# Evaluation on test data\n",
    "y_test_pred = ensemble_model.predict(X_test)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "print(f\"\\nTesting Data Performance:\")\n",
    "print(f\"R² Score: {test_r2:.4f}\")\n",
    "print(f\"MAE: {test_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
